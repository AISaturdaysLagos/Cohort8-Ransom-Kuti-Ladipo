{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: filelock in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: sympy in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchprofile\n",
      "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torchprofile) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.4 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torchprofile) (2.1.0)\n",
      "Collecting torchvision>=0.4\n",
      "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.0.106)\n",
      "Requirement already satisfied: sympy in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (1.12)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2.18.1)\n",
      "Requirement already satisfied: networkx in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.2.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
      "Requirement already satisfied: filelock in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->torchprofile) (12.3.52)\n",
      "Requirement already satisfied: requests in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from requests->torchvision>=0.4->torchprofile) (2.0.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
      "Installing collected packages: pillow, torchvision, torchprofile\n",
      "Successfully installed pillow-10.1.0 torchprofile-0.0.4 torchvision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "%pip install torch --quiet\n",
    "%pip install torchprofile --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torchprofile import profile_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.randn((10, 32, 5))  # (sequence_length, batch_size, input_dim)\n",
    "tgt = torch.randn((20, 32, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"doc\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, number_vocab=1000, max_len=100, number_hidden=64):\n",
    "        super().__init__()\n",
    "        self.postional_embedding_layers = nn.Embedding(number_vocab, number_hidden)\n",
    "        self.embedding_layers = nn.Embedding(max_len, number_hidden)\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        max_len = input_x.size()[-1]\n",
    "        input_x = self.embedding_layers(input_x)\n",
    "        # Generate positions using torch.arange\n",
    "        positions = torch.arange(0, max_len)\n",
    "        positions = self.postional_embedding_layers(positions)\n",
    "        return input_x + positions\n",
    "\n",
    "\n",
    "class LandmarkEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim = None, number_hidden=64, max_len=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=number_hidden,\n",
    "            kernel_size=11,\n",
    "            padding=\"same\",\n",
    "            stride=1,\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=number_hidden,\n",
    "            out_channels=number_hidden,\n",
    "            kernel_size=11,\n",
    "            padding=\"same\",\n",
    "            stride=1,\n",
    "        )\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=number_hidden,\n",
    "            out_channels=number_hidden,\n",
    "            kernel_size=11,\n",
    "            padding=\"same\",\n",
    "            stride=1,\n",
    "        )\n",
    "        self.postions_embedding_layers = nn.Embedding(max_len, number_hidden)\n",
    "        self.seq_nn = nn.Sequential(\n",
    "            self.conv1, nn.ReLU(), self.conv2, nn.ReLU(), self.conv3, nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        outputs = self.seq_nn(input_x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        no_multi_heads=6,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        num_encoder_layers = num_decoder_layers = 6\n",
    "        encoder_forward_dim = 100\n",
    "        # Define encoder and decoder layers\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=no_multi_heads,\n",
    "            dim_feedforward=encoder_forward_dim,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=no_multi_heads,\n",
    "            dim_feedforward=output_dim,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "\n",
    "        # Define encoder and decoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            self.decoder_layer, num_layers=num_decoder_layers\n",
    "        )\n",
    "\n",
    "        # Input and output linear layers\n",
    "        self.input_linear = LandmarkEmbedding(input_dim=input_dim,max_len=source_maxlen)\n",
    "        self.target_linear = TokenEmbedding(max_len=target_maxlen)\n",
    "        self.num_classes = 60\n",
    "        self.output_linear = nn.Linear(output_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, input_x, input_y):\n",
    "        # Apply EMbedding\n",
    "        input_x = self.input_linear(input_x)\n",
    "\n",
    "        # Transformer encoding\n",
    "        memory = self.transformer_encoder(input_x)\n",
    "\n",
    "        # Apply linear layer to the target\n",
    "        input_y = self.target_linear(input_y)\n",
    "\n",
    "        # Transformer decoding\n",
    "        output = self.transformer_decoder(input_y, memory)\n",
    "\n",
    "        # Apply linear layer to the output\n",
    "        output = self.output_linear(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # TODO code generate for inference\n",
    "    def generate(\n",
    "        self,\n",
    "    ):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m tgt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((batch_size, input_dim, input_dim))\u001b[39m.\u001b[39mlong()   \u001b[39m# (sequence_length, batch_size, input_dim)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m output \u001b[39m=\u001b[39m model(src, tgt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Print the output shape\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOutput shape:\u001b[39m\u001b[39m\"\u001b[39m, output\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder(input_x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m# Apply linear layer to the target\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m input_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_linear(input_y)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# Transformer decoding\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_decoder(input_y, memory)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_x):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     max_len \u001b[39m=\u001b[39m input_x\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     input_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_layers(input_x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Generate positions using torch.arange\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a372e7373682e77732d65753130352e676974706f642e696f222c2275736572223a2272696c65796472697a7a792d636f686f72743872616e732d6f626b726f766270317a37227d/workspace/Cohort8-Ransom-Kuti-Ladipo/linguify_yb/development/dev.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     positions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, max_len)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "#RuntimeError: Given groups=1, weight of size [11, 64, 2], \n",
    "#expected input[100, 32, 513] to have 64 channels, but got 32 channels instead\n",
    "# Example usage:\n",
    "input_dim = 513  # Adjust based on your input dimension\n",
    "output_dim = 256  # Adjust based on your output dimension\n",
    "nhead = 9\n",
    "batch_size = 16\n",
    "sequnce = 100\n",
    "# Instantiate the model\n",
    "model = Transformer(input_dim, output_dim,no_multi_heads=nhead)\n",
    "\n",
    "# Create dummy input\n",
    "src = torch.randn((batch_size, input_dim, input_dim))  # (sequence_length, batch_size, input_dim)\n",
    "tgt = torch.randn((batch_size, input_dim, input_dim)).long()  # (sequence_length, batch_size, input_dim)\n",
    "\n",
    "# Forward pass\n",
    "output = model(src, tgt)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error, the configuration is valid.\n"
     ]
    }
   ],
   "source": [
    "input_dim = 513\n",
    "num_heads = 9\n",
    "\n",
    "# Check if embed_dim is divisible by num_heads\n",
    "if input_dim % num_heads != 0:\n",
    "    print(\"Error: embed_dim must be divisible by num_heads\")\n",
    "else:\n",
    "    print(\"No error, the configuration is valid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = torch.arange(0, 100)\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app_title-D-s_o9_K-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
